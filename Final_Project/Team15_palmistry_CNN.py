# -*- coding: utf-8 -*-
"""Palmistry.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qOBXs8kU-LowhJ_fLjer1-WAwVsIapRs
"""

from google.colab import drive
from importlib import reload  # Py3 only; unneeded in py2.

drive = reload(drive)
drive.mount('/content/drive', force_remount=True)

from fastai.vision import *
from fastai.metrics import error_rate

from sklearn.metrics import confusion_matrix

from google.colab import files
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

from google.colab import files

from pathlib import Path
from glob2 import glob
import pandas as pd
import numpy as np
import os
import zipfile as zf
import shutil
import re
import seaborn as sns
import random as ran

# files = zf.ZipFile("./drive/My Drive/dataset-resized.zip",'r')
# files.extractall()
# files.close()
# os.listdir(os.path.join(os.getcwd(),"dataset-resized"))

!ls drive/My\ Drive

path_csv = 'drive/My Drive/Response4.xlsx 的副本'
# data_csv = pd.read_csv(path_csv)
data_csv = pd.read_excel(path_csv)
print(data_csv)

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)


# downloaded = drive.CreateFile({'id': "1MMvuEKKwJlE8IRabv_3l25Bn9vsrILhp"})

# Commented out IPython magic to ensure Python compatibility.
from PIL import Image, ExifTags
# %pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import functools
from scipy.ndimage import gaussian_filter

def image_transpose_exif(im):
    """
        Apply Image.transpose to ensure 0th row of pixels is at the visual
        top of the image, and 0th column is the visual left-hand side.
        Return the original image if unable to determine the orientation.

        As per CIPA DC-008-2012, the orientation field contains an integer,
        1 through 8. Other values are reserved.
    """

    exif_orientation_tag = 0x0112
    exif_transpose_sequences = [                   # Val  0th row  0th col
        [],                                        #  0    (reserved)
        [],                                        #  1   top      left
        [Image.FLIP_LEFT_RIGHT],                   #  2   top      right
        [Image.ROTATE_180],                        #  3   bottom   right
        [Image.FLIP_TOP_BOTTOM],                   #  4   bottom   left
        [Image.FLIP_LEFT_RIGHT, Image.ROTATE_90],  #  5   left     top
        [Image.ROTATE_270],                        #  6   right    top
        [Image.FLIP_TOP_BOTTOM, Image.ROTATE_90],  #  7   right    bottom
        [Image.ROTATE_90],                         #  8   left     bottom
    ]

    try:
        seq = exif_transpose_sequences[im._getexif()[exif_orientation_tag]]
    except Exception:
        return im
    else:
        return functools.reduce(type(im).transpose, seq, im)

def convertjpg(jpgfile,width=384,height=512):
    try :
        image = Image.open(jpgfile)
        
        image = image_transpose_exif(image) # rotate image (some picture will be rotated after resizing, need to rotate back)
        image = image.convert('LA') # convert to grayscale
        image=image.resize((width, height), Image.ANTIALIAS) # resize image

        os.remove(os.path.join(os.getcwd(), jpgfile))
        
        img_convert = np.array(image)
        img_c = gaussian_filter(img_convert, sigma=0.7) # Gaussian Filter
        image = Image.fromarray(img_c )
        
        image.save(jpgfile)
        return 1

    except Exception as e:
        print(e)
        return 0



import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import functools

!rm -r first second 
!mkdir -p first second 
# !mv mnist_test.csv ./top30
# !cd /content/top30
# !ls 
cnt1, cnt2, cnt3 = 1, 1, 1

for row in  data_csv.index:
    # grade = data_csv.loc[row, "生理性別"]
    grade = data_csv.loc[row, "平均成績％數"]
    pic_ID = data_csv.loc[row, "左手的掌心照"]
    
    pic_ID = pic_ID[pic_ID.find("id")+3:]
    if pic_ID in ["1L-DTFqfoj0MKAyG1MCIBYuC0tCTUNby1", "1saw4I-6_Oo-37tOcSqq5ceLA-WIz_vj4", "1invk7pqN5BeaXBtXa3gQRTZ7vICmm08F", "1UrImTDWGqBPHtP4fzREf77i7Kow7w23t", "1aPl6uKvUYwGL-yt6I1x8ILDVONdFJTeU", "1Cf9lkd89gRhDbJxl9POhPFPWy8uGVcgG", "1FwU9BEojTnnCZ_k2NwmUzukuyAl_LkB6", "1EmWAdyIoK7QZ7I9wkK1tSXiY6K4V1zHS" ]:
        continue
    # print(pic_ID)
    downloaded = drive.CreateFile({'id': pic_ID})
    print(pic_ID)

    if grade=="0-10%" or grade=="11-20%" or grade=="21-30%" or grade=="31-40%":
        pic_name = "first_" + str(cnt1) + ".png"
        print(pic_name)
        downloaded.GetContentFile(pic_name)
        succ = convertjpg(pic_name)
        if succ==0:
            os.remove(os.getcwd()+"/"+pic_name)
            continue;
        cnt1 += 1

        img=mpimg.imread(pic_name)
        imgplot = plt.imshow(img)
        plt.show()
        shutil.move(pic_name, "first/")
    
    else:
        pic_name = "second_" + str(cnt2) + ".png"
        print(pic_name)
        downloaded.GetContentFile(pic_name)
        succ = convertjpg(pic_name)
        if succ==0:
            os.remove(os.getcwd()+"/"+pic_name)
            continue;
        cnt2 += 1

        img=mpimg.imread(pic_name)
        imgplot = plt.imshow(img)
        plt.show()
        shutil.move(pic_name, "second/")


## helper functions ##

## splits indices for a folder into train, validation, and test indices with random sampling
    ## input: folder path
    ## output: train, valid, and test indices    
def split_indices(folder,seed1,seed2):    
    n = len(os.listdir(folder))
    
        
    full_set = list(range(1,n+1))

    ## train indices
    ran.seed(seed1)
    train = ran.sample(list(range(1,n+1)),int(.5*n))

    ## temp
    remain = list(set(full_set)-set(train))
    # valid = list(set(full_set)-set(train))

    ## separate remaining into validation and test
    ran.seed(seed2)
    valid = ran.sample(remain,int(.5*len(remain)))
    test = list(set(remain)-set(valid))
    
    return(train,valid, test)

## gets file names for a particular type of trash, given indices
    ## input: waste category and indices
    ## output: file names 
def get_names(waste_type,indices):
    file_names = [waste_type+"_"+str(i)+".png" for i in indices]
    return(file_names)    

## moves group of source files to another folder
    ## input: list of source files and destination folder
    ## no output
def move_files(source_files,destination_folder):
    for file in source_files:
        shutil.copy(file,destination_folder)

## paths will be train/cardboard, train/glass, etc...
subsets = ['train','valid']

grade_types = ['first', 'second']
!rm -r data/train data/valid data/test
## create destination folders for data subset and waste type
for subset in subsets:
    for grade_type in grade_types:
        folder = os.path.join('data',subset,grade_type)
        if not os.path.exists(folder):
            os.makedirs(folder)
            
if not os.path.exists(os.path.join('data','test')):
    os.makedirs(os.path.join('data','test'))
            
## move files to destination folders for each waste type
for grade_type in grade_types:
    source_folder = grade_type
    train_ind, valid_ind, test_ind = split_indices(source_folder,1,1)
    
    ## move source files to train
    train_names = get_names(grade_type,train_ind)
    train_source_files = [os.path.join(source_folder,name) for name in train_names]
    train_dest = "data/train/"+grade_type
    move_files(train_source_files,train_dest)
    
    ## move source files to valid
    valid_names = get_names(grade_type,valid_ind)
    valid_source_files = [os.path.join(source_folder,name) for name in valid_names]
    valid_dest = "data/valid/"+grade_type
    move_files(valid_source_files,valid_dest)
    
    ## move source files to test
    test_names = get_names(grade_type,test_ind)
    test_source_files = [os.path.join(source_folder,name) for name in test_names]
    ## I use data/test here because the images can be mixed up
    move_files(test_source_files,"data/test")

## get a path to the folder with images
path = Path(os.getcwd())/"data"
print(path)

tfms = get_transforms(do_flip=True,flip_vert=True)
data = ImageDataBunch.from_folder(path,test="test", bs=20)
# data = ImageDataBunch.from_folder(path, bs=40)
data

data.show_batch(rows=5, figsize=(8,10))

learn = cnn_learner(data,models.resnet34, metrics=[error_rate], callback_fns=ShowGraph)
learn.model

learn.lr_find(start_lr=1e-7,end_lr=1e1)
learn.recorder.plot(suggestion=True)

DatasetType.Train

learn.fit_one_cycle(20,max_lr=3.02E-03)

interp = ClassificationInterpretation.from_learner(learn)
losses,idxs = interp.top_losses()
interp.plot_top_losses(9, heatmap=True, figsize=(15,11))

interp.plot_confusion_matrix(figsize=(8,8), dpi=60)

preds = learn.get_preds(ds_type=DatasetType.Valid)
print( len(preds[0]))


# preds = learn.get_preds()

## saves the index (0 to 5) of most likely (max) predicted class for each image
max_idxs = np.asarray(np.argmax(preds[0],axis=1))

yhat = []
for max_idx in max_idxs:
    yhat.append(data.classes[max_idx])
print(yhat)
print(preds[1])

y = []

## convert POSIX paths to string first
for label_path in data.valid_ds.items:
    y.append(str(label_path))
print(len(y))
## then extract type from file path
pattern = re.compile("([a-z]+)_[0-9]+")
for i in range(len(y)):
    y[i] = pattern.search(y[i]).group(1)

## predicted values
print(yhat[0:5])
## actual values
print(y[0:5])

cm = confusion_matrix(y,yhat, labels=["first", "second"])
print(cm)
df_cm = pd.DataFrame(cm,grade_types,grade_types)

plt.figure(figsize=(10,8))
sns.heatmap(df_cm,annot=True,fmt="d",cmap="YlGnBu")

correct = 0

for r in range(len(cm)):
    for c in range(len(cm)):
        
        if (r==c):
            correct += cm[r,c]
accuracy = correct/sum(sum(cm))
print(accuracy)

fpr = dict()
tpr = dict()
roc_auc = dict()
import numpy as np
from sklearn import metrics

# print(y)
y_ = pd.get_dummies(y)
# print(y_)
# print(y_.iloc[:,1])
# print(preds[0][:])
# print(preds[0][:,0])
# print(y_.iloc[:,0])

for i in range(2):
    fpr[i], tpr[i], _ = metrics.roc_curve( y_.iloc[:, i], preds[0][:,i] ) 
    roc_auc[i] = metrics.auc(fpr[i], tpr[i])
plt.figure()
lw = 2
col = ['darkorange', 'green', 'red']
for i in range(2):
    plt.plot(fpr[i], tpr[i], color=col[i],
            lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[i])
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC curve')
plt.legend(loc="lower right")
plt.show()

